hits <- document
for (patterns in 1:length(names(hits))) {
patternHits <- hits[patterns]
patternID <- names(hits[patterns])
for (pattern in patternHits) {
# Skip patterns with no hits -----
if (length(pattern) == 0) {
next
} else {
# Patterns with hits -----
for (y in 1:(length(pattern))) {
for (texmatch in pattern[[y]]['matches']) {
for (z in 1:length(texmatch)) {
texmatch[[z]][['matchEntities']] <- (stringr::str_c(as.character(texmatch[[z]][['matchEntities']]), collapse = ' | '))
hitdf <- as.data.frame(do.call("cbind", texmatch[[z]]), stringsAsFactors=FALSE)
hitdf$DocID <- as.factor(docid)
hitdf$patternID <- as.factor(patternID)
allHitsDF <- plyr::rbind.fill(allHitsDF, hitdf)
}
}
}
}
}
}
}
}
}
# Output -----
test <- as.numeric(allHitsDF$hitCount)
print (test)
return(allHitsDF)
}
texpressDF <- texpress_hits_from_json(texpressResponse)
texpress_hits_from_json <- function(texpress_json_response) {
allHitsDF = data.frame()
# Error Handling ----
if (('RESP_TEXPRESS' %in% names(texpress_json_response)) == FALSE) stop("No TExpress hits in JSON response")
# Payload processing -----
if ('RESP_TEXPRESS' %in% names(texpress_json_response)) {
for (x in 1:(length(texpress_json_response[['RESP_TEXPRESS']]))) {
texpressHits <- texpress_json_response[['RESP_TEXPRESS']][x]
docid <- names(texpressHits)
for (document in texpressHits) {
hits <- document
for (patterns in 1:length(names(hits))) {
patternHits <- hits[patterns]
patternID <- names(hits[patterns])
for (pattern in patternHits) {
# Skip patterns with no hits -----
if (length(pattern) == 0) {
next
} else {
# Patterns with hits -----
for (y in 1:(length(pattern))) {
for (texmatch in pattern[[y]]['matches']) {
for (z in 1:length(texmatch)) {
texmatch[[z]][['matchEntities']] <- (stringr::str_c(as.character(texmatch[[z]][['matchEntities']]), collapse = ' | '))
hitdf <- as.data.frame(do.call("cbind", texmatch[[z]]), stringsAsFactors=FALSE)
hitdf$DocID <- as.factor(docid)
hitdf$patternID <- as.factor(patternID)
allHitsDF <- plyr::rbind.fill(allHitsDF, hitdf)
}
}
}
}
}
}
}
}
}
# Output -----
allHitsDF$hitCount <- as.numeric(allHitsDF$hitCount)
return(allHitsDF)
}
texpressDF <- texpress_hits_from_json(texpressResponse)
texpressDF <- texpress_hits_from_json(texpressResponse)
texpress_hits_from_json <- function(texpress_json_response) {
allHitsDF = data.frame()
# Error Handling ----
if (('RESP_TEXPRESS' %in% names(texpress_json_response)) == FALSE) stop("No TExpress hits in JSON response")
# Payload processing -----
if ('RESP_TEXPRESS' %in% names(texpress_json_response)) {
for (x in 1:(length(texpress_json_response[['RESP_TEXPRESS']]))) {
texpressHits <- texpress_json_response[['RESP_TEXPRESS']][x]
docid <- names(texpressHits)
for (document in texpressHits) {
hits <- document
for (patterns in 1:length(names(hits))) {
patternHits <- hits[patterns]
patternID <- names(hits[patterns])
for (pattern in patternHits) {
# Skip patterns with no hits -----
if (length(pattern) == 0) {
next
} else {
# Patterns with hits -----
for (y in 1:(length(pattern))) {
for (texmatch in pattern[[y]]['matches']) {
for (z in 1:length(texmatch)) {
texmatch[[z]][['matchEntities']] <- (stringr::str_c(as.character(texmatch[[z]][['matchEntities']]), collapse = ' | '))
hitdf <- as.data.frame(do.call("cbind", texmatch[[z]]), stringsAsFactors=FALSE)
hitdf$DocID <- as.factor(docid)
hitdf$patternID <- as.factor(patternID)
allHitsDF <- plyr::rbind.fill(allHitsDF, hitdf)
}
}
}
}
}
}
}
}
}
# Output -----
transform(allHitsDF, start = as.numeric(start), end = as.numeric(end))
return(allHitsDF)
}
texpressDF <- texpress_hits_from_json(texpressResponse)
texpress_hits_from_json <- function(texpress_json_response) {
allHitsDF = data.frame()
# Error Handling ----
if (('RESP_TEXPRESS' %in% names(texpress_json_response)) == FALSE) stop("No TExpress hits in JSON response")
# Payload processing -----
if ('RESP_TEXPRESS' %in% names(texpress_json_response)) {
for (x in 1:(length(texpress_json_response[['RESP_TEXPRESS']]))) {
texpressHits <- texpress_json_response[['RESP_TEXPRESS']][x]
docid <- names(texpressHits)
for (document in texpressHits) {
hits <- document
for (patterns in 1:length(names(hits))) {
patternHits <- hits[patterns]
patternID <- names(hits[patterns])
for (pattern in patternHits) {
# Skip patterns with no hits -----
if (length(pattern) == 0) {
next
} else {
# Patterns with hits -----
for (y in 1:(length(pattern))) {
for (texmatch in pattern[[y]]['matches']) {
for (z in 1:length(texmatch)) {
texmatch[[z]][['matchEntities']] <- (stringr::str_c(as.character(texmatch[[z]][['matchEntities']]), collapse = ' | '))
hitdf <- as.data.frame(do.call("cbind", texmatch[[z]]), stringsAsFactors=FALSE)
hitdf$DocID <- as.factor(docid)
hitdf$patternID <- as.factor(patternID)
allHitsDF <- plyr::rbind.fill(allHitsDF, hitdf)
}
}
}
}
}
}
}
}
}
# Output -----
allHitsDF <- transform(allHitsDF, start = as.numeric(start), end = as.numeric(end))
return(allHitsDF)
}
texpressDF <- texpress_hits_from_json(texpressResponse)
texpress_hits_from_json <- function(texpress_json_response) {
allHitsDF = data.frame()
# Error Handling ----
if (('RESP_TEXPRESS' %in% names(texpress_json_response)) == FALSE) stop("No TExpress hits in JSON response")
# Payload processing -----
if ('RESP_TEXPRESS' %in% names(texpress_json_response)) {
for (x in 1:(length(texpress_json_response[['RESP_TEXPRESS']]))) {
texpressHits <- texpress_json_response[['RESP_TEXPRESS']][x]
docid <- names(texpressHits)
for (document in texpressHits) {
hits <- document
for (patterns in 1:length(names(hits))) {
patternHits <- hits[patterns]
patternID <- names(hits[patterns])
for (pattern in patternHits) {
# Skip patterns with no hits -----
if (length(pattern) == 0) {
next
} else {
# Patterns with hits -----
for (y in 1:(length(pattern))) {
for (texmatch in pattern[[y]]['matches']) {
for (z in 1:length(texmatch)) {
texmatch[[z]][['matchEntities']] <- (stringr::str_c(as.character(texmatch[[z]][['matchEntities']]), collapse = ' | '))
hitdf <- as.data.frame(do.call("cbind", texmatch[[z]]), stringsAsFactors=FALSE)
hitdf$DocID <- as.factor(docid)
hitdf$patternID <- as.factor(patternID)
allHitsDF <- plyr::rbind.fill(allHitsDF, hitdf)
}
}
}
}
}
}
}
}
}
# Output -----
allHitsDF <- transform(allHitsDF, start = as.numeric(start),
end = as.numeric(end),
forward = as.factor(forward),
negative = as.factor(negative),
conf = as.numeric(conf),
sentence = as.numeric(sentence),
patternName = as.factor(patternName)
originalFragmentStart = as.numeric(originalFragmentStart),
originalFragmentEnd = as.numeric(originalFragmentEnd))
return(allHitsDF)
}
texpress_hits_from_json <- function(texpress_json_response) {
allHitsDF = data.frame()
# Error Handling ----
if (('RESP_TEXPRESS' %in% names(texpress_json_response)) == FALSE) stop("No TExpress hits in JSON response")
# Payload processing -----
if ('RESP_TEXPRESS' %in% names(texpress_json_response)) {
for (x in 1:(length(texpress_json_response[['RESP_TEXPRESS']]))) {
texpressHits <- texpress_json_response[['RESP_TEXPRESS']][x]
docid <- names(texpressHits)
for (document in texpressHits) {
hits <- document
for (patterns in 1:length(names(hits))) {
patternHits <- hits[patterns]
patternID <- names(hits[patterns])
for (pattern in patternHits) {
# Skip patterns with no hits -----
if (length(pattern) == 0) {
next
} else {
# Patterns with hits -----
for (y in 1:(length(pattern))) {
for (texmatch in pattern[[y]]['matches']) {
for (z in 1:length(texmatch)) {
texmatch[[z]][['matchEntities']] <- (stringr::str_c(as.character(texmatch[[z]][['matchEntities']]), collapse = ' | '))
hitdf <- as.data.frame(do.call("cbind", texmatch[[z]]), stringsAsFactors=FALSE)
hitdf$DocID <- as.factor(docid)
hitdf$patternID <- as.factor(patternID)
allHitsDF <- plyr::rbind.fill(allHitsDF, hitdf)
}
}
}
}
}
}
}
}
}
# Output -----
allHitsDF <- transform(allHitsDF, start = as.numeric(start),
end = as.numeric(end),
forward = as.factor(forward),
negative = as.factor(negative),
conf = as.numeric(conf),
sentence = as.numeric(sentence),
patternName = as.factor(patternName),
originalFragmentStart = as.numeric(originalFragmentStart),
originalFragmentEnd = as.numeric(originalFragmentEnd))
return(allHitsDF)
}
texpressDF <- texpress_hits_from_json(texpressResponse)
View(texpressDF)
get_entity_hits_from_json <- function(termite_json_response,
columns_to_return = c("hitID", "entityType", "name", "hitCount", "totnosyns", "goodSynCount",
"realSynList", "score", "exact_string", "frag_vector_array")) {
allHitsDF = data.frame()
# Payload processing -----
if ('RESP_MULTIDOC_PAYLOAD' %in% names(termite_json_response)) {
# Multidoc processing -----
columns_to_return <- append(columns_to_return, c("docID"))
for (document in termite_json_response[['RESP_MULTIDOC_PAYLOAD']]) {
for (entity_type in document) {
columnNames <- (names(entity_type[[1]]))
grabInfo <- function(var) {
# Source: http://zevross.com/blog/2015/02/12/using-r-to-download-and-parse-json-an-example-using-data-from-an-open-data-portal/
sapply(entity_type, function(x) returnData(x, var))
}
returnData <- function(x, var) {
# get data - entries with multiple values are converted to pipe separated character
# Source: http://zevross.com/blog/2015/02/12/using-r-to-download-and-parse-json-an-example-using-data-from-an-open-data-portal/
if(!is.null( x[[var]])){
if (!is.list(typeof(x[[var]]))) {
return(stringr::str_c(as.character(x[[var]]), collapse = ' | '))
}
}else{
return(NA)
}
}
# get values and return dataframe
entityHits <- as.vector(sapply(columnNames, grabInfo), mode = "character")
entityHitsDF <- as.data.frame(matrix(entityHits, ncol=length(columnNames)), stringsAsFactors=FALSE)
colnames(entityHitsDF) <- columnNames
allHitsDF <- plyr::rbind.fill(allHitsDF, entityHitsDF)
}
}
} else {
# Single payload processing -----
for (entity_type in termite_json_response[['RESP_PAYLOAD']]) {
columnNames <- (names(entity_type[[1]]))
grabInfo <- function(var) {
#print(paste("Variable", var, sep=" "))
sapply(entity_type, function(x) returnData(x, var))
}
returnData <- function(x, var) {
# get data - entries with multiple values are converted to pipe separated character
# Source: http://zevross.com/blog/2015/02/12/using-r-to-download-and-parse-json-an-example-using-data-from-an-open-data-portal/
if(!is.null( x[[var]])){
if (!is.list(typeof(x[[var]]))) {
return(stringr::str_c(as.character(x[[var]]), collapse = ' | '))
}
} else {
return(NA)
}
}
# get values and return dataframe
entityHits <- as.vector(sapply(columnNames, grabInfo), mode = "character") # extraction of data from all columns and assembly into vector
entityHitsDF <- as.data.frame(matrix(entityHits, ncol=length(columnNames)), stringsAsFactors=FALSE)
colnames(entityHitsDF) <- columnNames
allHitsDF <- plyr::rbind.fill(allHitsDF, entityHitsDF)
}
}
# Output -----
returnDF <- allHitsDF#[, columns_to_return]
return(returnDF)
}
responseDF <- get_entity_hits_from_json(termiteResponse)
get_entity_hits_from_json <- function(termite_json_response,
columns_to_return = c("hitID", "entityType", "name", "hitCount", "totnosyns", "goodSynCount",
"realSynList", "score", "exact_string", "frag_vector_array")) {
allHitsDF = data.frame()
# Payload processing -----
if ('RESP_MULTIDOC_PAYLOAD' %in% names(termite_json_response)) {
# Multidoc processing -----
columns_to_return <- append(columns_to_return, c("docID"))
for (document in termite_json_response[['RESP_MULTIDOC_PAYLOAD']]) {
for (entity_type in document) {
columnNames <- (names(entity_type[[1]]))
grabInfo <- function(var) {
# Source: http://zevross.com/blog/2015/02/12/using-r-to-download-and-parse-json-an-example-using-data-from-an-open-data-portal/
sapply(entity_type, function(x) returnData(x, var))
}
returnData <- function(x, var) {
# get data - entries with multiple values are converted to pipe separated character
# Source: http://zevross.com/blog/2015/02/12/using-r-to-download-and-parse-json-an-example-using-data-from-an-open-data-portal/
if(!is.null( x[[var]])){
if (!is.list(typeof(x[[var]]))) {
return(stringr::str_c(as.character(x[[var]]), collapse = ' | '))
}
}else{
return(NA)
}
}
# get values and return dataframe
entityHits <- as.vector(sapply(columnNames, grabInfo), mode = "character")
entityHitsDF <- as.data.frame(matrix(entityHits, ncol=length(columnNames)), stringsAsFactors=FALSE)
colnames(entityHitsDF) <- columnNames
allHitsDF <- plyr::rbind.fill(allHitsDF, entityHitsDF)
}
}
} else {
# Single payload processing -----
for (entity_type in termite_json_response[['RESP_PAYLOAD']]) {
columnNames <- (names(entity_type[[1]]))
grabInfo <- function(var) {
#print(paste("Variable", var, sep=" "))
sapply(entity_type, function(x) returnData(x, var))
}
returnData <- function(x, var) {
# get data - entries with multiple values are converted to pipe separated character
# Source: http://zevross.com/blog/2015/02/12/using-r-to-download-and-parse-json-an-example-using-data-from-an-open-data-portal/
if(!is.null( x[[var]])){
if (!is.list(typeof(x[[var]]))) {
return(stringr::str_c(as.character(x[[var]]), collapse = ' | '))
}
} else {
return(NA)
}
}
# get values and return dataframe
entityHits <- as.vector(sapply(columnNames, grabInfo), mode = "character") # extraction of data from all columns and assembly into vector
entityHitsDF <- as.data.frame(matrix(entityHits, ncol=length(columnNames)), stringsAsFactors=FALSE)
colnames(entityHitsDF) <- columnNames
allHitsDF <- plyr::rbind.fill(allHitsDF, entityHitsDF)
}
}
# Output -----
allHitsDF <- transform(allHitsDF, invalidPositions = as.factor(invalidPositions),
hitCount = as.numeric(hitCount),
totnosyns = as.numeric(totnosyns),
goodSynCount = as.numeric(goodSynCount),
nonambigsuns = as.numeric(nonambigsuns),
score = as.numeric(score),
entityType = as.factor(entityType),
rejected = as.factor(rejected),
dependencyMet = as.factor(dependencyMet),
fuzzyMatches = as.numeric(fuzzyMatches))
returnDF <- allHitsDF[, columns_to_return]
return(returnDF)
}
responseDF <- get_entity_hits_from_json(termiteResponse)
get_entity_hits_from_json <- function(termite_json_response,
columns_to_return = c("hitID", "entityType", "name", "hitCount", "totnosyns", "goodSynCount",
"realSynList", "score", "exact_string", "frag_vector_array")) {
allHitsDF = data.frame()
# Payload processing -----
if ('RESP_MULTIDOC_PAYLOAD' %in% names(termite_json_response)) {
# Multidoc processing -----
columns_to_return <- append(columns_to_return, c("docID"))
for (document in termite_json_response[['RESP_MULTIDOC_PAYLOAD']]) {
for (entity_type in document) {
columnNames <- (names(entity_type[[1]]))
grabInfo <- function(var) {
# Source: http://zevross.com/blog/2015/02/12/using-r-to-download-and-parse-json-an-example-using-data-from-an-open-data-portal/
sapply(entity_type, function(x) returnData(x, var))
}
returnData <- function(x, var) {
# get data - entries with multiple values are converted to pipe separated character
# Source: http://zevross.com/blog/2015/02/12/using-r-to-download-and-parse-json-an-example-using-data-from-an-open-data-portal/
if(!is.null( x[[var]])){
if (!is.list(typeof(x[[var]]))) {
return(stringr::str_c(as.character(x[[var]]), collapse = ' | '))
}
}else{
return(NA)
}
}
# get values and return dataframe
entityHits <- as.vector(sapply(columnNames, grabInfo), mode = "character")
entityHitsDF <- as.data.frame(matrix(entityHits, ncol=length(columnNames)), stringsAsFactors=FALSE)
colnames(entityHitsDF) <- columnNames
allHitsDF <- plyr::rbind.fill(allHitsDF, entityHitsDF)
}
}
} else {
# Single payload processing -----
for (entity_type in termite_json_response[['RESP_PAYLOAD']]) {
columnNames <- (names(entity_type[[1]]))
grabInfo <- function(var) {
#print(paste("Variable", var, sep=" "))
sapply(entity_type, function(x) returnData(x, var))
}
returnData <- function(x, var) {
# get data - entries with multiple values are converted to pipe separated character
# Source: http://zevross.com/blog/2015/02/12/using-r-to-download-and-parse-json-an-example-using-data-from-an-open-data-portal/
if(!is.null( x[[var]])){
if (!is.list(typeof(x[[var]]))) {
return(stringr::str_c(as.character(x[[var]]), collapse = ' | '))
}
} else {
return(NA)
}
}
# get values and return dataframe
entityHits <- as.vector(sapply(columnNames, grabInfo), mode = "character") # extraction of data from all columns and assembly into vector
entityHitsDF <- as.data.frame(matrix(entityHits, ncol=length(columnNames)), stringsAsFactors=FALSE)
colnames(entityHitsDF) <- columnNames
allHitsDF <- plyr::rbind.fill(allHitsDF, entityHitsDF)
}
}
# Output -----
allHitsDF <- transform(allHitsDF, invalidPositions = as.factor(invalidPositions),
hitCount = as.numeric(hitCount),
totnosyns = as.numeric(totnosyns),
goodSynCount = as.numeric(goodSynCount),
nonambigsyns = as.numeric(nonambigsyns),
score = as.numeric(score),
entityType = as.factor(entityType),
rejected = as.factor(rejected),
dependencyMet = as.factor(dependencyMet),
fuzzyMatches = as.numeric(fuzzyMatches))
returnDF <- allHitsDF[, columns_to_return]
return(returnDF)
}
responseDF <- get_entity_hits_from_json(termiteResponse)
library(SciBiteR)
endpoint <- "http://localhost:9090/termite"
input <- "PAXIP1 Potentiates the Combination of WEE1 Inhibitor AZD1775 and Platinum Agents in Lung Cancer. The DNA damage response (DDR) involves a complex network of signaling events mediated by modular protein domains such as the BRCA1 C-terminal (BRCT) domain. Thus, proteins that interact with BRCT domains and are a part of the DDR constitute potential targets for sensitization to DNA-damaging chemotherapy agents. We performed a pharmacologic screen to evaluate 17 kinases, identified in a BRCT-mediated interaction network as targets to enhance platinum-based chemotherapy in lung cancer. Inhibition of mitotic kinase WEE1 was found to have the most effective response in combination with platinum compounds in lung cancer cell lines. In the BRCT-mediated interaction network, WEE1 was found in complex with PAXIP1, a protein containing six BRCT domains involved in transcription and in the cellular response to DNA damage. We show that PAXIP1 BRCT domains regulate WEE1-mediated phosphorylation of CDK1. Furthermore, ectopic expression of PAXIP1 promotes enhanced caspase-3-mediated apoptosis in cells treated with WEE1 inhibitor AZD1775 (formerly, MK-1775) and cisplatin compared with cells treated with AZD1775 alone. Cell lines and patient-derived xenograft models expressing both PAXIP1 and WEE1 exhibited synergistic effects of AZD1775 and cisplatin. In summary, PAXIP1 is involved in sensitizing lung cancer cells to the WEE1 inhibitor AZD1775 in combination with platinum-based treatment. We propose that WEE1 and PAXIP1 levels may be used as mechanism-based biomarkers of response when WEE1 inhibitor AZD1775 is combined with DNA-damaging agents. "
inputFile <- FALSE
inputFileFormat <- NULL
outputFile <- NULL
outputFormat <- "json"
VOCabs <- NULL
options <- list("subsume" = "false", "rejectAmbig" = "true")
termiteResponse <- TERMite(endpoint="http://localhost:9090/termite",
input = input,
inputFile = inputFile,
inputFileFormat = inputFileFormat,
outputFile = outputFile,
outputFormat = outputFormat,
VOCabs = VOCabs,
options = options)
responseDF <- get_entity_hits_from_json(termiteResponse)
View(responseDF)
endpoint <- "http://localhost:9090/texpress"
input <- "/Users/rachaelturner/Documents/Atopic_Dermatitis/PatternScore_Notebook/Pubmed_miniSample.xml"
inputFile <- TRUE
inputFileFormat <- "pubmed"
outputFile <- NULL
outputFormat <- "json"
pattern <- NULL
bundle <- "drugapproval"
options <- list("subsume" = "false", "rejectAmbig" = "true")
texpressResponse <- TExpress(endpoint=endpoint,
input = input,
inputFile = inputFile,
inputFileFormat = inputFileFormat,
outputFile = outputFile,
outputFormat = outputFormat,
pattern = pattern,
bundle = bundle,
options = options)
texpressDF <- texpress_hits_from_json(texpressResponse)
View(texpressDF)
library(SciBiteR)
